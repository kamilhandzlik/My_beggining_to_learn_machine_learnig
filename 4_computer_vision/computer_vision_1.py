# Pytorch computer vision
# CNN - Convolutional Neural Network
"""
CNN to specjalny rodzaj sztucznej sieci neuronowej, kt√≥ry zosta≈Ç zaprojektowany z my≈õlƒÖ o przetwarzaniu danych o strukturze siatki,
 takich jak obrazy (dwuwymiarowe siatki pikseli). Ich g≈Ç√≥wnym celem jest automatyczne wykrywanie istotnych cech w danych wej≈õciowych,
   bez konieczno≈õci rƒôcznego projektowania tzw. feature extractor√≥w.

Dziƒôki mechanizmowi splotu (convolution), CNN potrafi:

wykrywaƒá krawƒôdzie, kszta≈Çty i tekstury na wczesnych warstwach,

rozpoznawaƒá bardziej z≈Ço≈ºone wzory (np. twarz, samoch√≥d, litera) w warstwach g≈Çƒôbszych.

Innymi s≈Çowy, CNN to mistrz wzrokowy w ≈õwiecie algorytm√≥w - Sherlock Holmes analizujƒÖcy ka≈ºdy piksel jakby by≈Ç wskaz√≥wkƒÖ w zagadce.
"""

# Architektura CNN
"""
Tradycyjna architektura CNN sk≈Çada siƒô z kilku klasycznych komponent√≥w, kt√≥re - jak to w porzƒÖdnej orkiestrze - majƒÖ swoje role i rytm dzia≈Çania:

1. Warstwa wej≈õciowa (Input Layer)
Przyjmuje dane - np. obraz 32x32 piksele z 3 kana≈Çami (RGB).

Reprezentacja: 32 x 32 x 3

2. Warstwy splotowe (Convolutional Layers)
G≈Ç√≥wna atrakcja CNN.

Nak≈ÇadajƒÖ filtry (jƒÖdra) na obraz, przesuwajƒÖc siƒô po nim i tworzƒÖc mapy cech (feature maps).

Ka≈ºdy filtr wykrywa inny wzorzec: poziome krawƒôdzie, okrƒôgi, faktury itd.

‚û°Ô∏è Reprezentacja przekszta≈Çca siƒô: 32 x 32 x 3 ‚Üí 28 x 28 x 16, 24 x 24 x 32 itd. (zale≈ºnie od rozmiaru filtra i kroku stride).

3. Funkcja aktywacji (najczƒô≈õciej ReLU)
Wprowadza nieliniowo≈õƒá (≈ºeby nie sko≈Ñczyƒá z czym≈õ, co przypomina tylko liniowƒÖ regresjƒô).

Pomaga modelowi lepiej dopasowaƒá siƒô do skomplikowanych danych.

4. Warstwy sp≈ÇaszczajƒÖce (Pooling Layers - np. MaxPooling)
RedukujƒÖ wymiary map cech (czyli rozmiar danych), ale zachowujƒÖ najwa≈ºniejsze informacje.

Dzia≈ÇajƒÖ jak starannie przemy≈õlany minimalizm: mniej danych, ale wiƒôcej sensu.

5. Warstwa sp≈ÇaszczajƒÖca (Flatten)
Przekszta≈Çca dane z formatu przestrzennego (np. 6 x 6 x 64) do p≈Çaskiego wektora (np. 2304 elementy).

Gotowe do przetworzenia przez klasyczne sieci neuronowe.

6. Warstwy w pe≈Çni po≈ÇƒÖczone (Fully Connected - Dense Layers)
Typowa perceptronowa sieƒá neuronowa na ko≈Ñcu.

Odpowiada za klasyfikacjƒô lub regresjƒô - np. rozpoznanie, ≈ºe na obrazku jest pies, kot lub tost (je≈õli CNN mia≈Ç z≈Çy dzie≈Ñ üòâ).

7. Warstwa wyj≈õciowa (Output Layer)
Zawiera tyle neuron√≥w, ile klas chcemy rozpoznaƒá (np. 10 w przypadku CIFAR-10).

Zwykle zako≈Ñczona funkcjƒÖ softmax (w klasyfikacji wieloklasowej), kt√≥ra przekszta≈Çca wyniki w prawdopodobie≈Ñstwa.

Przyk≈Çad Architektury CNN (dla obrazu 32x32x3)
text
Kopiuj
Edytuj
Input (32x32x3)
‚Üì
Conv2D (filter=3x3, depth=32) + ReLU
‚Üì
MaxPooling2D (2x2)
‚Üì
Conv2D (filter=3x3, depth=64) + ReLU
‚Üì
MaxPooling2D (2x2)
‚Üì
Flatten
‚Üì
Dense (128) + ReLU
‚Üì
Dense (10) + Softmax ‚Üí Output



WƒÖ≈ºne biblioteki, kt√≥re powiniene≈õ poznaƒá:
- torchvision  - baza z kt√≥rej korzystasz
- torchvision.dataset - ≈Çadowanie i tworzenie danych
- torchvision.models - u≈ºywanie ju≈º wytrenowanych modeli
- torchvision.trandforms - dostosowywanie obraz√≥w tak, ≈ºeby model m√≥g≈Ç je czytaƒá
- torch.utils.data.Dataset
- torch.utils.data.DataLoader
"""

import torch
from torch import nn
from torch.utils.data import DataLoader
import torchvision
from torchvision import datasets
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt
import os
import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from helper_function import accuracy_fn

# 1. Przygotowanie danych
# Dataset, kt√≥rego u≈ºyje to FashionMNIST - ekwiwalent do Hello World! XD

# 1.1 Pobieranie Danych z fashionMNIST do folderu data
train_data = datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=torchvision.transforms.ToTensor(),
    target_transform=None,
)
test_data = datasets.FashionMNIST(
    root="data",
    train=False,
    download=True,
    transform=ToTensor(),
    target_transform=None,
)

RANDOM_SEED = 42
# device = "cuda" if torch.cuda.is_available() else "cpu"
# Sprawdzenie czy jest podzia≈Ç
print(f"len Train data: {len(train_data)}, len test data: {len(test_data)}")

# Sprawdzenie w jakiej formie sƒÖ zapisane obrazy
image, label = train_data[0]
# print(f"Image: {train_data[0]}")
# Sprawdzenie jakie mamy klasy
class_names = train_data.classes
class_to_idx = train_data.class_to_idx

# print(class_names)
# print(class_to_idx)
# print(train_data.targets)

print(f"Image shape: {image.shape} [Colorchannels, height, witht]")
print(f"Label shape: {class_names[label]}")

# Tak z ciekawo≈õci chcƒô zobaczyƒá jak m√≥k image wyglƒÖda w wykresie matplotlib
# Pamiƒôstaj, ≈ºe image ma wymiary [kolor, szeroko≈õƒá, wysoko≈õƒá] matplotlib kolor ma na ko≈Ñcu wiƒôc musisz zmieniƒá Tensor ≈ºeby nie mieƒá shape errora

## odkomentuj ≈ºeby zobaczyƒá obrazek
# plt.imshow(image.squeeze(), cmap="gray")
# plt.title(class_names[label])
# plt.axis(False)
# plt.show()

## odkomentuj ≈ºeby zobaczyƒá obrazek
torch.manual_seed(RANDOM_SEED)
# fig = plt.figure(figsize=(9, 9))
# rows, cols = 4, 4
# for i in range(1, rows * cols + 1):
#     random_idx = torch.randint(0, len(train_data), size=[1]).item()
#     img, label = train_data[random_idx]
#     fig.add_subplot(rows, cols, i)
#     plt.imshow(img.squeeze(), cmap="gray")
#     plt.title(class_names[label])
#     plt.axis(False)
# plt.show()

## Prepare DataLoader
"""
W tej chwili dane sƒÖ w formie Pytorch Dataset i trzeba przerobiƒá je na dane iterowalne przez pythona.

Now we've got a dataset ready to go.

The next step is to prepare it with a torch.utils.data.DataLoader or DataLoader for short.

The DataLoader does what you think it might do.

It helps load data into a model.

For training and for inference.

It turns a large Dataset into a Python iterable of smaller chunks.

These smaller chunks are called batches or mini-batches and can be set by the batch_size parameter.

Why do this?

Because it's more computationally efficient.

In an ideal world you could do the forward pass and backward pass across all of your data at once.

But once you start using really large datasets, unless you've got infinite computing power, it's easier to break them up into batches.

It also gives your model more opportunities to improve.

With mini-batches (small portions of the data), gradient descent is performed more often per epoch (once per mini-batch rather than once per epoch).

What's a good batch size?

32 is a good place to start for a fair amount of problems.

But since this is a value you can set (a hyperparameter) you can try all different kinds of values,
 though generally powers of 2 are used most often (e.g. 32, 64, 128, 256, 512).
"""

BATCH_SIZE = 32

train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)

# Odkomentuj ≈ºeby zobaczyƒá datalodery jak wyglƒÖdajƒÖ, rozmiary pr√≥bek
# print(f"Dataloaders: {train_dataloader, test_dataloader}")
# print(f"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}")
# print(f"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}")


# Sprawdzenie co jest w ≈õrodku dataloader√≥:
train_features_batch, train_labels_batch = next(iter(train_dataloader))
print(train_features_batch.shape, train_labels_batch.shape)

# Show Samples
# torch.manual_seed(RANDOM_SEED)
# random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()
# img, labels = train_features_batch[random_idx], train_labels_batch[random_idx]
# plt.imshow(img.squeeze(), cmap="gray")
# plt.title(class_names[label])
# plt.axis(False)
# plt.show()
# print(f"Image size: {img.shape}")
# print(f"Label: {label}, label size: {label.shape}")


# 3. Budowanie modelu
# flatten layer
flatten_model = nn.Flatten()

# Get a single sample
x = train_features_batch[0]

# Flatten the sample
output = flatten_model(x)

# Print out what happend
# print(f"Shape before flatteining: {x.shape}")
# print(f"Shpae after flattening; {output.shape}")


# Model
class FashionMNISTModelV0(nn.Module):
    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):
        super().__init__()
        self.layer_stack = nn.Sequential(
            nn.Flatten(),
            nn.Linear(in_features=input_shape, out_features=hidden_units),
            nn.Linear(in_features=hidden_units, out_features=output_shape),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.layer_stack(x)


torch.manual_seed(RANDOM_SEED)
model_0 = FashionMNISTModelV0(input_shape=784, hidden_units=10, output_shape=10).to(
    "cpu"
)


# 4. Testing loop
epochs = 3

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)

# Creating to time our experiments
from timeit import default_timer


def print_train_time(start: float, end: float, device: torch.device = None):
    total_time = end - start
    print(f"Train time on {device}: {total_time:.3f} seconds")
    return total_time


start_time = default_timer()
end_time = default_timer()
print(print_train_time(start=start_time, end=end_time, device="cpu"))


from tqdm.auto import tqdm

torch.manual_seed(RANDOM_SEED)
train_time_star_on_cpu = default_timer()

# Training and testing loops
for epoch in tqdm(range(epochs)):
    print(f"Epoch: {epoch}\n------------")
    train_loss = 0
    # Trainig loop
    for batch, (X, y) in enumerate(train_dataloader):
        model_0.train()
        # 1. Forward pass
        y_pred = model_0(X)
        # 2. Calculate the loss
        loss = loss_fn(y_pred, y)
        train_loss += loss
        # 3. optimizer zero grad
        optimizer.zero_grad()
        # 4. Backward propagation
        loss.backward()
        # 5. Optimizer step
        optimizer.step()

        if batch % 400 == 0:
            print(f"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples")

    # Divide total train loss by length of train dataloader (average loss per batch per epoch)
    train_loss /= len(train_dataloader)

    # Testing loop
    # Setup variables for accumulatively adding up loss and accuracy
    test_loss, test_acc = 0, 0
    model_0.eval()
    with torch.inference_mode():
        for X, y in test_dataloader:
            test_pred = model_0(X)
            test_loss += loss_fn(test_pred, y).item()
            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))
        test_loss /= len(test_dataloader)
        test_acc /= len(test_dataloader)
    print(
        f"\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.2f}, Test acc: {test_acc:.2f}%\n"
    )

# Calculate training time
train_time_end_on_cpu = default_timer()
total_train_time_model_0 = print_train_time(
    start=train_time_star_on_cpu,
    end=train_time_end_on_cpu,
    device=str(next(model_0.parameters()).device),
)

#  4. Make predictions and get Model 0 results
torch.manual_seed(RANDOM_SEED)


def eval_model(
    model: torch.nn.Module,
    data_loader: torch.utils.data.DataLoader,
    loss_fn: torch.nn.Module,
    accuracy_fn,
):
    loss, acc = 0, 0
    model.eval()
    with torch.inference_mode():
        for X, y in tqdm(data_loader):
            y_pred = model(X)
            loss += loss_fn(y_pred, y)
            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))

        loss /= len(data_loader)
        acc /= len(data_loader)

    return {
        "model_name": model.__class__.__name__,
        "model_loss": loss.item(),
        "model_acc": acc,
    }


#  Calculating model 0 result on test dataset.
model_0_results = eval_model(
    model=model_0, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn
)
# No to do tego momentu by≈Ç przyk≈Çad jak to wszystko dzia≈Ça na cpu czas przej≈õƒá na gpu
# print(model_0_results)

# 5 Setup device agnostic code
device = "cude" if torch.cuda.is_available else "cpu"
