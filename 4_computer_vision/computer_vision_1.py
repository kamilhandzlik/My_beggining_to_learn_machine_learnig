# Pytorch computer vision
# CNN - Convolutional Neural Network
"""
CNN to specjalny rodzaj sztucznej sieci neuronowej, ktÃ³ry zostaÅ‚ zaprojektowany z myÅ›lÄ… o przetwarzaniu danych o strukturze siatki,
 takich jak obrazy (dwuwymiarowe siatki pikseli). Ich gÅ‚Ã³wnym celem jest automatyczne wykrywanie istotnych cech w danych wejÅ›ciowych,
   bez koniecznoÅ›ci rÄ™cznego projektowania tzw. feature extractorÃ³w.

DziÄ™ki mechanizmowi splotu (convolution), CNN potrafi:

wykrywaÄ‡ krawÄ™dzie, ksztaÅ‚ty i tekstury na wczesnych warstwach,

rozpoznawaÄ‡ bardziej zÅ‚oÅ¼one wzory (np. twarz, samochÃ³d, litera) w warstwach gÅ‚Ä™bszych.

Innymi sÅ‚owy, CNN to mistrz wzrokowy w Å›wiecie algorytmÃ³w - Sherlock Holmes analizujÄ…cy kaÅ¼dy piksel jakby byÅ‚ wskazÃ³wkÄ… w zagadce.
"""

# Architektura CNN
"""
Tradycyjna architektura CNN skÅ‚ada siÄ™ z kilku klasycznych komponentÃ³w, ktÃ³re - jak to w porzÄ…dnej orkiestrze - majÄ… swoje role i rytm dziaÅ‚ania:

1. Warstwa wejÅ›ciowa (Input Layer)
Przyjmuje dane - np. obraz 32x32 piksele z 3 kanaÅ‚ami (RGB).

Reprezentacja: 32 x 32 x 3

2. Warstwy splotowe (Convolutional Layers)
GÅ‚Ã³wna atrakcja CNN.

NakÅ‚adajÄ… filtry (jÄ…dra) na obraz, przesuwajÄ…c siÄ™ po nim i tworzÄ…c mapy cech (feature maps).

KaÅ¼dy filtr wykrywa inny wzorzec: poziome krawÄ™dzie, okrÄ™gi, faktury itd.

â¡ï¸ Reprezentacja przeksztaÅ‚ca siÄ™: 32 x 32 x 3 â†’ 28 x 28 x 16, 24 x 24 x 32 itd. (zaleÅ¼nie od rozmiaru filtra i kroku stride).

3. Funkcja aktywacji (najczÄ™Å›ciej ReLU)
Wprowadza nieliniowoÅ›Ä‡ (Å¼eby nie skoÅ„czyÄ‡ z czymÅ›, co przypomina tylko liniowÄ… regresjÄ™).

Pomaga modelowi lepiej dopasowaÄ‡ siÄ™ do skomplikowanych danych.

4. Warstwy spÅ‚aszczajÄ…ce (Pooling Layers - np. MaxPooling)
RedukujÄ… wymiary map cech (czyli rozmiar danych), ale zachowujÄ… najwaÅ¼niejsze informacje.

DziaÅ‚ajÄ… jak starannie przemyÅ›lany minimalizm: mniej danych, ale wiÄ™cej sensu.

5. Warstwa spÅ‚aszczajÄ…ca (Flatten)
PrzeksztaÅ‚ca dane z formatu przestrzennego (np. 6 x 6 x 64) do pÅ‚askiego wektora (np. 2304 elementy).

Gotowe do przetworzenia przez klasyczne sieci neuronowe.

6. Warstwy w peÅ‚ni poÅ‚Ä…czone (Fully Connected - Dense Layers)
Typowa perceptronowa sieÄ‡ neuronowa na koÅ„cu.

Odpowiada za klasyfikacjÄ™ lub regresjÄ™ - np. rozpoznanie, Å¼e na obrazku jest pies, kot lub tost (jeÅ›li CNN miaÅ‚ zÅ‚y dzieÅ„ ğŸ˜‰).

7. Warstwa wyjÅ›ciowa (Output Layer)
Zawiera tyle neuronÃ³w, ile klas chcemy rozpoznaÄ‡ (np. 10 w przypadku CIFAR-10).

Zwykle zakoÅ„czona funkcjÄ… softmax (w klasyfikacji wieloklasowej), ktÃ³ra przeksztaÅ‚ca wyniki w prawdopodobieÅ„stwa.

PrzykÅ‚ad Architektury CNN (dla obrazu 32x32x3)
text
Kopiuj
Edytuj
Input (32x32x3)
â†“
Conv2D (filter=3x3, depth=32) + ReLU
â†“
MaxPooling2D (2x2)
â†“
Conv2D (filter=3x3, depth=64) + ReLU
â†“
MaxPooling2D (2x2)
â†“
Flatten
â†“
Dense (128) + ReLU
â†“
Dense (10) + Softmax â†’ Output



WÄ…Å¼ne biblioteki, ktÃ³re powinieneÅ› poznaÄ‡:
- torchvision  - baza z ktÃ³rej korzystasz
- torchvision.dataset - Å‚adowanie i tworzenie danych
- torchvision.models - uÅ¼ywanie juÅ¼ wytrenowanych modeli
- torchvision.trandforms - dostosowywanie obrazÃ³w tak, Å¼eby model mÃ³gÅ‚ je czytaÄ‡
- torch.utils.data.Dataset
- torch.utils.data.DataLoader
"""

import torch
from torch import nn
from torch.utils.data import DataLoader
import torchvision
from torchvision import datasets
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt

# 1. Przygotowanie danych
# Dataset, ktÃ³rego uÅ¼yje to FashionMNIST - ekwiwalent do Hello World! XD

# 1.1 Pobieranie Danych z fashionMNIST do folderu data
train_data = datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=torchvision.transforms.ToTensor(),
    target_transform=None,
)
test_data = datasets.FashionMNIST(
    root="data",
    train=False,
    download=True,
    transform=ToTensor(),
    target_transform=None,
)

RANDOM_SEED = 42
# Sprawdzenie czy jest podziaÅ‚
print(f"len Train data: {len(train_data)}, len test data: {len(test_data)}")

# Sprawdzenie w jakiej formie sÄ… zapisane obrazy
image, label = train_data[0]
# print(f"Image: {train_data[0]}")
# Sprawdzenie jakie mamy klasy
class_names = train_data.classes
class_to_idx = train_data.class_to_idx

# print(class_names)
# print(class_to_idx)
# print(train_data.targets)

print(f"Image shape: {image.shape} [Colorchannels, height, witht]")
print(f"Label shape: {class_names[label]}")

# Tak z ciekawoÅ›ci chcÄ™ zobaczyÄ‡ jak mÃ³k image wyglÄ…da w wykresie matplotlib
# PamiÄ™staj, Å¼e image ma wymiary [kolor, szerokoÅ›Ä‡, wysokoÅ›Ä‡] matplotlib kolor ma na koÅ„cu wiÄ™c musisz zmieniÄ‡ Tensor Å¼eby nie mieÄ‡ shape errora

## odkomentuj Å¼eby zobaczyÄ‡ obrazek
# plt.imshow(image.squeeze(), cmap="gray")
# plt.title(class_names[label])
# plt.axis(False)
# plt.show()

## odkomentuj Å¼eby zobaczyÄ‡ obrazek
torch.manual_seed(RANDOM_SEED)
# fig = plt.figure(figsize=(9, 9))
# rows, cols = 4, 4
# for i in range(1, rows * cols + 1):
#     random_idx = torch.randint(0, len(train_data), size=[1]).item()
#     img, label = train_data[random_idx]
#     fig.add_subplot(rows, cols, i)
#     plt.imshow(img.squeeze(), cmap="gray")
#     plt.title(class_names[label])
#     plt.axis(False)
# plt.show()

## Prepare DataLoader
"""
W tej chwili dane sÄ… w formie Pytorch Dataset i trzeba przerobiÄ‡ je na dane iterowalne przez pythona.

Now we've got a dataset ready to go.

The next step is to prepare it with a torch.utils.data.DataLoader or DataLoader for short.

The DataLoader does what you think it might do.

It helps load data into a model.

For training and for inference.

It turns a large Dataset into a Python iterable of smaller chunks.

These smaller chunks are called batches or mini-batches and can be set by the batch_size parameter.

Why do this?

Because it's more computationally efficient.

In an ideal world you could do the forward pass and backward pass across all of your data at once.

But once you start using really large datasets, unless you've got infinite computing power, it's easier to break them up into batches.

It also gives your model more opportunities to improve.

With mini-batches (small portions of the data), gradient descent is performed more often per epoch (once per mini-batch rather than once per epoch).

What's a good batch size?

32 is a good place to start for a fair amount of problems.

But since this is a value you can set (a hyperparameter) you can try all different kinds of values,
 though generally powers of 2 are used most often (e.g. 32, 64, 128, 256, 512).
"""

BATCH_SIZE = 32

train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)

# Odkomentuj Å¼eby zobaczyÄ‡ datalodery jak wyglÄ…dajÄ…, rozmiary prÃ³bek
# print(f"Dataloaders: {train_dataloader, test_dataloader}")
# print(f"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}")
# print(f"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}")


# Sprawdzenie co jest w Å›rodku dataloaderÃ³:
train_features_batch, train_labels_batch = next(iter(train_dataloader))
print(train_features_batch.shape, train_labels_batch.shape)

# Show Samples
# torch.manual_seed(RANDOM_SEED)
# random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()
# img, labels = train_features_batch[random_idx], train_labels_batch[random_idx]
# plt.imshow(img.squeeze(), cmap="gray")
# plt.title(class_names[label])
# plt.axis(False)
# plt.show()
# print(f"Image size: {img.shape}")
# print(f"Label: {label}, label size: {label.shape}")
